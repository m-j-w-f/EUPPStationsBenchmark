{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation\n",
    "This is used to generate the benchmark data for the EUPPBench Station Post Processing Benchmark, containint a Reforecast to Reforecst (*R2R*)and Reforecast to Forecast (*R2F*) task.\n",
    "\n",
    "## Prerequisites\n",
    "Download the [EUPPBench Dataset](https://zenodo.org/records/7708362), unzip it \n",
    "```shell\n",
    "unzip EUPPBench-stations.zip\n",
    "rm EUPPBench-stations.zip\n",
    "```\n",
    "\n",
    "## Data Split\n",
    "Reforecasts:\n",
    "- Train: [1997-2013]\n",
    "- Test: [2014-2017]\n",
    "\n",
    "Forecasts:\n",
    "- Test: [2017-2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Union, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZarrLoader:\n",
    "    \"\"\"\n",
    "    A class for loading data from Zarr files.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): The path to the data directory.\n",
    "\n",
    "    Attributes:\n",
    "        data_path (str): The path to the data directory.\n",
    "        countries (List[str]): The list of countries to load data for.\n",
    "        features (List[str]): The list of features to load.\n",
    "\n",
    "    Methods:\n",
    "        get_stations(arr: xr.Dataset) -> pd.DataFrame:\n",
    "            Get the stations information from the dataset.\n",
    "\n",
    "        load_data(countries: Union[str, List[str]] = \"all\",\n",
    "        features: Union[str, List[str]] = \"all\")\n",
    "        -> Tuple[xr.Dataset, xr.Dataset, xr.Dataset, xr.Dataset]:\n",
    "            Load the data from Zarr files.\n",
    "\n",
    "        validate_stations() -> bool:\n",
    "            Validate if the station IDs match between forecasts and reforecasts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str) -> None:\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def get_stations(self, arr: xr.Dataset) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get the stations information from the dataset.\n",
    "\n",
    "        Args:\n",
    "            arr (xr.Dataset): The dataset containing station information.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The dataframe containing station information.\n",
    "        \"\"\"\n",
    "        stations = pd.DataFrame(\n",
    "            {\n",
    "                \"station_id\": arr.station_id.values,\n",
    "                \"lat\": arr.station_latitude.values,\n",
    "                \"lon\": arr.station_longitude.values,\n",
    "                \"altitude\": arr.station_altitude.values,\n",
    "                \"name\": arr.station_name.values,\n",
    "            }\n",
    "        )\n",
    "        stations = stations.sort_values(\"station_id\").reset_index(drop=True)\n",
    "        return stations\n",
    "    \n",
    "    def _fix_time(self, ds: xr.Dataset) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Fixes the time dimension of the given xr dataset by subtracting the year values from the time values.\n",
    "        Use for reforecasts data.\n",
    "        \n",
    "        Args:\n",
    "            ds (xr.Dataset): The input dataset with a 'year' and 'time' dimension.\n",
    "\n",
    "        Returns:\n",
    "            xr.Dataset: The modified dataset with a new time dimension.\n",
    "\n",
    "        \"\"\"\n",
    "        new_times = []\n",
    "        for year in ds.year.values:\n",
    "            # Convert to Pandas DatetimeIndex\n",
    "            dates_pd = pd.DatetimeIndex(ds.time.values)\n",
    "            # Subtract years\n",
    "            dates_subtracted = dates_pd - pd.DateOffset(years=year)\n",
    "            new_times.append(dates_subtracted.values)\n",
    "\n",
    "        new_times = np.concatenate(new_times)\n",
    "        # Create a new dataset with the combined time dimension\n",
    "        ds_new = ds.stack(new_time=('year', 'time'))\n",
    "        # Assign the new time values\n",
    "        ds_new = ds_new.drop_vars(['new_time', 'year', 'time'])\n",
    "        ds_new = ds_new.assign_coords(new_time=new_times)\n",
    "        # Sort the dataset by the new time coordinate\n",
    "        ds_new = ds_new.sortby('new_time')\n",
    "        # Rename 'new_time' to 'time'\n",
    "        ds_new = ds_new.rename({'new_time': 'time'})\n",
    "        return ds_new\n",
    "\n",
    "    def load_data(\n",
    "        self, countries: Union[str, List[str]] = \"all\", features: Union[str, List[str]] = \"all\"\n",
    "    ) -> Tuple[xr.Dataset, xr.Dataset, xr.Dataset, xr.Dataset]:\n",
    "        \"\"\"\n",
    "        Load data for the specified lead time, countries, and features.\n",
    "\n",
    "        Args:\n",
    "            countries (Union[str, List[str]]): The countries for which to load the data. Default is \"all\".\n",
    "            features (Union[str, List[str]]): The features to load. Default is \"all\".\n",
    "\n",
    "        Returns:\n",
    "            Tuple[xr.Dataset, xr.Dataset, xr.Dataset, xr.Dataset]:\n",
    "            A tuple containing the following datasets:\n",
    "                - df_f: The forecasts dataset.\n",
    "                - df_f_target: The targets for the forecasts dataset.\n",
    "                - df_rf: The reforecasts dataset.\n",
    "                - df_rf_target: The targets for the reforecasts dataset.\n",
    "        \"\"\"\n",
    "        if countries == \"all\":\n",
    "            print(\"[INFO] Loading data for all countries\")\n",
    "            self.countries = [\"austria\", \"belgium\", \"france\", \"germany\", \"netherlands\"]\n",
    "        elif isinstance(countries, list):\n",
    "            print(f\"[INFO] Loading data for {countries}\")\n",
    "            self.countries = countries\n",
    "        else:\n",
    "            raise ValueError(\"countries must be a list of strings or 'all'\")\n",
    "\n",
    "        if features == \"all\":\n",
    "            print(\"[INFO] Loading all features\")\n",
    "            self.features = [\"number\"] + [\n",
    "                \"station_id\",\n",
    "                \"time\",\n",
    "                \"cape\",\n",
    "                \"model_orography\",\n",
    "                \"sd\",\n",
    "                \"station_altitude\",\n",
    "                \"station_latitude\",\n",
    "                \"station_longitude\",\n",
    "                \"stl1\",\n",
    "                \"swvl1\",\n",
    "                \"t2m\",\n",
    "                \"tcc\",\n",
    "                \"tcw\",\n",
    "                \"tcwv\",\n",
    "                \"u10\",\n",
    "                \"u100\",\n",
    "                \"v10\",\n",
    "                \"v100\",\n",
    "                \"vis\",\n",
    "                \"cp6\",\n",
    "                \"mn2t6\",\n",
    "                \"mx2t6\",\n",
    "                \"p10fg6\",\n",
    "                \"slhf6\",\n",
    "                \"sshf6\",\n",
    "                \"ssr6\",\n",
    "                \"ssrd6\",\n",
    "                \"str6\",\n",
    "                \"strd6\",\n",
    "                \"tp6\",\n",
    "                \"z\",\n",
    "                \"q\",\n",
    "                \"u\",\n",
    "                \"v\",\n",
    "                \"t\",\n",
    "            ]\n",
    "        elif isinstance(features, list):\n",
    "            print(f\"[INFO] Loading features: {features}\")\n",
    "            self.features = [\"number\"] + features\n",
    "        else:\n",
    "            raise ValueError(\"features must be a list of strings or 'all'\")\n",
    "\n",
    "        # Load Data from Zarr ####\n",
    "        all_countries = {'forecasts': [], 'reforecasts': []}\n",
    "        targets_all_countries = {'forecasts': [], 'reforecasts': []}\n",
    "        \n",
    "        forecasts_xrs = {}\n",
    "        targets_xrs = {}\n",
    "        \n",
    "        for pred in ['forecasts', 'reforecasts']:\n",
    "            print(f\"[INFO] Loading {pred}\")\n",
    "            for country in self.countries:\n",
    "                # Forecasts\n",
    "                surface_xr = xr.open_zarr(f\"{self.data_path}/stations_ensemble_{pred}_surface_{country}.zarr\")\n",
    "                surface_pp_xr = xr.open_zarr(f\"{self.data_path}/stations_ensemble_{pred}_surface_postprocessed_{country}.zarr\")\n",
    "                pressure_500_xr = xr.open_zarr(f\"{self.data_path}/stations_ensemble_{pred}_pressure_500_{country}.zarr\")\n",
    "                pressure_700_xr = xr.open_zarr(f\"{self.data_path}/stations_ensemble_{pred}_pressure_700_{country}.zarr\")\n",
    "                pressure_850_xr = xr.open_zarr(f\"{self.data_path}/stations_ensemble_{pred}_pressure_850_{country}.zarr\")\n",
    "                obs_xr = xr.open_zarr(f\"{self.data_path}/stations_{pred}_observations_surface_{country}.zarr\")\n",
    "                \n",
    "                forecasts = [surface_xr, surface_pp_xr, pressure_500_xr, pressure_700_xr, pressure_850_xr]\n",
    "                forecasts = [forecast.drop_vars(\"valid_time\").squeeze(drop=True) for forecast in forecasts]\n",
    "                forecasts = xr.merge(forecasts)\n",
    "                all_countries[pred].append(forecasts)\n",
    "                \n",
    "                targets = obs_xr.squeeze(drop=True)\n",
    "                targets_all_countries[pred].append(targets)\n",
    "            \n",
    "            forecasts_xrs[pred] = xr.concat(all_countries[pred], dim=\"station_id\")\n",
    "            targets_xrs[pred] = xr.concat(targets_all_countries[pred], dim=\"station_id\")\n",
    "            \n",
    "            if pred == 'reforecasts':\n",
    "                tmp = self._fix_time(forecasts_xrs[pred])\n",
    "                forecasts_xrs[pred] = tmp.transpose('station_id', 'number',  'time', 'step')\n",
    "                tmp = self._fix_time(targets_xrs[pred])\n",
    "                targets_xrs[pred] = tmp.transpose('station_id', 'time', 'step') \n",
    "\n",
    "\n",
    "        print(\n",
    "            f\"[INFO] Data loaded successfully. Forecasts shape: {forecasts_xrs['forecasts'].t2m.shape}, Reforecasts shape: {forecasts_xrs['reforecasts'].t2m.shape}\"\n",
    "        )\n",
    "\n",
    "        # Extract Stations ####\n",
    "        self.stations_f = self.get_stations(forecasts_xrs['forecasts'])\n",
    "        self.stations_rf = self.get_stations(forecasts_xrs['reforecasts'])\n",
    "        return forecasts_xrs, targets_xrs\n",
    "\n",
    "    def validate_stations(self):\n",
    "        return (self.stations_f.station_id == self.stations_rf.station_id).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading data for all countries\n",
      "[INFO] Loading all features\n",
      "[INFO] Loading forecasts\n",
      "[INFO] Loading reforecasts\n",
      "[INFO] Data loaded successfully. Forecasts shape: (122, 51, 730, 21), Reforecasts shape: (122, 11, 4180, 21)\n"
     ]
    }
   ],
   "source": [
    "# Assuming the data is stored in the 'data' directory\n",
    "loader2 = ZarrLoader(data_path=\"data/EUPPBench-stations\")\n",
    "fc, targets = loader2.load_data(countries=\"all\", features=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x165475340>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data\n",
    "# Slice excludes last element\n",
    "train = fc[\"reforecasts\"].sel(time=slice('1997-01-01', '2014-01-01'))  # [1997-2013]\n",
    "test_rf = fc[\"reforecasts\"].sel(time=slice('2014-01-01', '2018-01-01'))  # [2014-2017]\n",
    "test_f = fc['forecasts'].sel(time=slice('2017-01-01', '2019-01-01'))  # [2017-2018]\n",
    "\n",
    "# Targets\n",
    "train_targets = targets[\"reforecasts\"].sel(time=slice('1997-01-01', '2014-01-01'))  # [1997-2013]\n",
    "test_rf_targets = targets[\"reforecasts\"].sel(time=slice('2014-01-01', '2018-01-01'))  # [2014-2017]\n",
    "test_f_targets = targets['forecasts'].sel(time=slice('2017-01-01', '2019-01-01'))  # [2017-2018]\n",
    "\n",
    "# Save to disk\n",
    "train.to_zarr(\"shared/train.zarr\", mode=\"w\")\n",
    "test_rf.to_zarr(\"shared/test_rf.zarr\", mode=\"w\")\n",
    "test_f.to_zarr(\"shared/test_f.zarr\", mode=\"w\")\n",
    "train_targets.to_zarr(\"shared/train_targets.zarr\", mode=\"w\")\n",
    "test_rf_targets.to_zarr(\"shared/test_rf_targets.zarr\", mode=\"w\")\n",
    "test_f_targets.to_zarr(\"shared/test_f_targets.zarr\", mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
